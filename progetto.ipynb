{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ac6821-3035-48c2-a76d-97b58d87b266",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"5\">Data Understanding</font>\n",
    "\n",
    "Questa fase consiste nell’ <b> identificazione </b>, <b>collezione</b> e <b>analisi</b> dei dataset che possono portare al raggiungimento degli obiettivi.\n",
    "Inoltre in questa fase ci occuperemo anche della <b>data visualization </b> e  <b> data quality </b>.\n",
    "\n",
    "La scelta proggettuale è stata quella di generare personalemente il dataset a partire da risorse trovate online. Gli Urls (phishing e legitimate) sono stati reperiti da diverse fonti ad esempio: PhishTank, Openphish e Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7005e-fa38-462e-9b68-169dd97483f2",
   "metadata": {},
   "source": [
    "<br>\n",
    "Importiamo le librerie utilizzate in questa fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7fddf-a350-4057-91d8-6daed1187d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libreria necessaria per utilizzare funzioni definite in notebook diversi\n",
    "#!pip install import-ipynb\n",
    "import import_ipynb\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path  \n",
    "import os\n",
    "from os import path\n",
    "import generateDataset\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a8960-228a-47dd-8f78-c00fb7a0781b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><font size=\"4\">Identificazione dei dataset</font></b>\n",
    "\n",
    "Nello specifico sono stati identificati 5 dataset.\n",
    "Due di questi vengono utilizzati per estrarre tutti gli <b>url leggittimi</b> (legitimate) e sono i seguenti:\n",
    "- dataset_phishing_and_legitimate.csv\n",
    "- dataset_phishing_and_legitimate2.csv\n",
    "\n",
    "mentre gli altri 3 dataset vengono utilizzati per estrarre tutti gli <b> url phishing </b> e sono i seguenti:\n",
    "- dataset_phishing.csv\n",
    "- dataset_phishing2.txt\n",
    "- openphish.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea72029-385e-4355-849f-291ae2d35085",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><font size=\"4\">Collezione dei dataset</font></b>\n",
    "\n",
    "<b><font size=\"2\">Eliminazione delle colonne inutili e concatenazione dei dataset</font></b>\n",
    "\n",
    "Come detto precedentemente la scelta proggettuale è quella di generare all'interno del progetto il dataset.\n",
    "Dunque quello che ci interessa nei dataset scaricati sono solo gli Url, gli altri dati possono essere scartati.\n",
    "\n",
    "Nel codice seguente andremo ad eliminare tutte le informazioni superflue e creeremo un unico dataset contenete i soli url e la loro classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ea6b3-750e-4b79-aacb-9cb136b53d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMO DATASET LEGITIMATE\n",
    "# caricamento del dataset ed estrazione di tutte le istanze legitimate da dataset_phishing_and_legitimate.csv\n",
    "data = pd.read_csv(\"./dataset/dataset_phishing_and_legitimate.csv\")\n",
    "legitimate_dataset1 = data.drop(data[data.status == \"phishing\"].index)\n",
    "\n",
    "#eliminazione delle feature(colonne)\n",
    "legitimate_dataset1 = legitimate_dataset1.drop(legitimate_dataset1.iloc[:, 1:88],axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# SECONDO DATASET LEGITIMATE\n",
    "# caricamento del secondo dataset ed estrazione di tutte le istanze legitimate da dataset_phishing_and_legitimate.csv\n",
    "\n",
    "data2 = pd.read_csv(\"./dataset/dataset_phishing_and_legitimate2.csv\")\n",
    "legitimate_dataset2 = data2.drop(data2[(data2['status'] == \"phishing\") | (data2['status'] == \"malware\") | (data2['status'] == \"defacement\") ].index)\n",
    "\n",
    "legitimate_dataset2 = legitimate_dataset2.head(60000)\n",
    "\n",
    "# shuffle dei dati\n",
    "legitimate_dataset2 =sklearn.utils.shuffle(legitimate_dataset2)\n",
    "\n",
    "#cambiamo benign con legitimate per avere dei valori consistenti\n",
    "legitimate_dataset2['status'] = legitimate_dataset2['status'].replace('benign', 'legitimate', regex=True)\n",
    "\n",
    "\n",
    "#concatenzaione dei due dataset Legitimate\n",
    "frame = [legitimate_dataset1, legitimate_dataset2]\n",
    "legitimate_dataset = pd.concat(frame)\n",
    "\n",
    "\n",
    "# PRIMO DATASET PHISHING\n",
    "# caricamento del dataset\n",
    "phishing_dataset1 = pd.read_csv(\"./dataset/dataset_phishing.csv\")\n",
    "\n",
    "#eliminazione della colonna id\n",
    "phishing_dataset1 = phishing_dataset1.drop(phishing_dataset1.columns[[0]],axis = 1)\n",
    "\n",
    "#eliminazione delle colonne restanti\n",
    "phishing_dataset1 = phishing_dataset1.drop(phishing_dataset1.iloc[:, 1:7],axis = 1)\n",
    "phishing_dataset1.insert(1, \"status\", \"phishing\", True)\n",
    "\n",
    "\n",
    "# SECONDO DATASET PHISHING\n",
    "# caricamento del dataset\n",
    "phishing_dataset2  = pd.read_csv('./dataset/openphish.txt', sep=\" \",header=None )\n",
    "phishing_dataset2.columns = [\"url\"]\n",
    "phishing_dataset2.insert(1, \"status\", \"phishing\", True)\n",
    "\n",
    "\n",
    "# TERZO DATASET PHISHING\n",
    "phishing_dataset3  = pd.read_csv('./dataset/dataset_phishing2.txt', sep=\" \",header=None )\n",
    "phishing_dataset3.columns = [\"url\"]\n",
    "phishing_dataset3.insert(1, \"status\", \"phishing\", True)\n",
    "\n",
    "# shuffle dei dati\n",
    "phishing_dataset3 =sklearn.utils.shuffle(phishing_dataset3)\n",
    "\n",
    "#estraiamo le prime 30000 istanze da phishing_dataset3\n",
    "phishing_dataset3 = phishing_dataset3.head(50163) \n",
    "\n",
    "\n",
    "#concateniamo i 3 dataset\n",
    "frames = [phishing_dataset1,phishing_dataset2,phishing_dataset3]\n",
    "phishing_dataset = pd.concat(frames)\n",
    "\n",
    "\n",
    "#concateniamo i 2 dataset, avendo cosi un unico dataset\n",
    "frames = [legitimate_dataset, phishing_dataset]\n",
    "dataset = pd.concat(frames)\n",
    "\n",
    "#eliminiamo \"www.\" da tutte le istanze del dataset\n",
    "dataset['url'] = dataset['url'].replace('www.', '', regex=True)\n",
    "\n",
    "# shuffle dei dati\n",
    "dataset=sklearn.utils.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0712194-5f06-45f2-bc75-f3f04a895833",
   "metadata": {},
   "source": [
    "<br>\n",
    "Il risultato di tali operazioni ci porterà alla creazione di un unico dataset con più di 128000 entry, un esempio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414ecea-a4e7-4f93-9b3c-ff27e6ed75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa481b1-5b61-42bf-9727-b6deae848da2",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><font size=\"4\">Generazione del dataset</font></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2828a6-5ab8-4a7f-b6bd-a28373d5f265",
   "metadata": {},
   "source": [
    "<br>\n",
    "Il dataset che adesso abbiamo a disposizione è formato unicamente da 2 colonne, ovvero l'url e lo status. \n",
    "Per creare un modello di Machine Learning abbiamo bisogno di estrarre delle caratteristiche (feature) dagli Url a disposizione.\n",
    "In questa fase ci occuperemo di estrarre le feature da ogni url.\n",
    "\n",
    "Il modulo che si occupa della creazione del dataset con le feature è il modulo <i>\"generateDataset\"</i>, mentre le funzioni che si occupano dell'estrazione delle feature vera e propria si trovano in <i>\"featureExtraction\"</i>\n",
    "\n",
    "Il progetto è consegnato con il dataset finale (ovvero già provvisto di feature) già generato, il quale è salvato nel file \"finalDataset.csv\". Tuttavia nel caso si volesse ri-generare il dataset finale, basta eliminare il file \"finalDataset.csv\", l'operazione potrebbe richiedere diversi minuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62550b-075c-46c1-88fb-95f405f94079",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"finalDataset.csv\"\n",
    "if path.exists(file) and os.path.getsize(file) != 0:\n",
    "    #legge da finalDataset.csv\n",
    "    print(\"Leggo da finalDataset.csv\")\n",
    "    finalDataset = pd.read_csv(file)\n",
    "else:\n",
    "    #crea il dataset\n",
    "    print(\"creo il dataset\")\n",
    "    finalDataset = generateDataset.generate(dataset,file)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bc0a5b-ccb8-4076-bca8-db772232d174",
   "metadata": {},
   "source": [
    "<br>\n",
    "Il risultato dell'estrazione delle feature, porta alla creazione del dataset su cui andremo a lavorare ovvero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f979c0-c963-49ff-9339-d17d6b224191",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cca2e9-e572-485c-bed7-6edf596eaf60",
   "metadata": {},
   "source": [
    "<br><b><font size=\"4\">Analisi del dataset</font></b>\n",
    "\n",
    "Dopo aver estratto gli Url dai vari dataset scaricati, e dopo aver estratto le feature da tutti gli Url, adesso andremo ad analizzare il dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5faf01-b593-4f56-9c3d-37bf4d28d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esaminiamo i dati \n",
    "finalDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b41fc3a-be0c-49ae-8f0e-6da6b7e01251",
   "metadata": {},
   "source": [
    "Avremo dunque 128308 entry, e 34 colonne di cui 32 sono le feature estratte.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2fc63-0ac8-41e3-a618-0645ad8ec962",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size=\"4\">Presenza duplicati</font>\n",
    "<br>\n",
    "\n",
    "Controlliamo la presenza di duplicati nel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01f254-8add-41db-a54a-98ddcda9acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = finalDataset.duplicated().sum()\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c66391-cd44-408f-8431-c7a5be8e1c29",
   "metadata": {},
   "source": [
    "Avremo dunque 197 duplicati nel dataset e nello specifico sono gli url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ff822-de76-48f0-aeaa-83e3c44b9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateRows = finalDataset[finalDataset.duplicated()]\n",
    "print (duplicateRows[\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af155fd-24fd-4d03-aaac-d7862b5e3872",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size=\"4\">Bilanciamento dei dati</font></b>\n",
    "\n",
    "Andiamo a visualizzare il bilanciamento dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5d30b-8811-4757-851f-c43384d6678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = finalDataset.label.value_counts()\n",
    "\n",
    "data = [count[\"legitimate\"], count[\"phishing\"]]\n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "plt.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "print(\"Numero url legitimate: \",count[\"legitimate\"])\n",
    "print(\"Numero url phishing: \" ,count[\"phishing\"])\n",
    "plt.title(\"Bilanciamento dati\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dcceda-d941-4311-b74f-f9634f6ffb6a",
   "metadata": {},
   "source": [
    "Avendo creato il dataset personalmente, lo abbiamo creato appositamente bilanciato<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c61a1c3-54a9-4440-96fa-d6be3141e361",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<font size=\"4\">Dati mancanti</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b4e01-371e-4299-ac87-446f6dd917f6",
   "metadata": {},
   "source": [
    "Controlliamo se abbiamo valori null all'interno del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4dbb6d-e4da-4ebf-8000-e9404d17e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f9c966-c17f-4677-bba8-9868d2d06780",
   "metadata": {},
   "source": [
    "Abbiamo 54422 entry con valore null per la feature \"https\" <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb0745-9e18-4fae-9365-432920b34cc7",
   "metadata": {},
   "source": [
    "<font size=\"4\">Ricerca outlier</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d576180-7f93-407b-adcb-7c2e7e208c09",
   "metadata": {},
   "source": [
    "In questa fase andremo a ricercare possibili outlier all'interno del dataset, utilizzeremo un box plot per osservare possibili outlier. <br>\n",
    "\n",
    "Utilizzo la feature \"urlLenght\" in quanto da questa dipendono la maggior parte delle feature, come ad esempio lenghtSub, lenghtPath, numLetters, ecc... Mentre non considero le altre feature in quanto sono valori booleani."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d88e61f-b164-41cc-92b4-01c1fd424bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDataset.urlLenght.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34614420-7a74-4179-9163-1e38c1984f1b",
   "metadata": {},
   "source": [
    "Già in questa fase possiamo notare che c'è almeno un elemento nel dataset che ha la feature \"urlLenght\" pari a 5787, mentre la media di tutti gli elementi è 56. Questo chiaramente indica la presenza di outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04bff7-cbfe-4116-922b-69f3d7b3cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(finalDataset, x = \"label\", y=\"urlLenght\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8aa45a-9804-4abc-b75e-1a1cacb04f22",
   "metadata": {},
   "source": [
    "Abbiamo conferma della presenza di outlier anche grazie a questo grafico.\n",
    "\n",
    "Guardando il grafico non riusciamo ad ottenre molte altre informazioni, tuttavia possiamo notare che ci sono altri outlier.\n",
    "\n",
    "Utilizzeremo l'IQR method per identificare gli altri outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3296d5-e6a6-4f5b-95c3-a98d90f624d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectOutliers(data):\n",
    "    quartile_1, quartile_3 = np.percentile(data[\"urlLenght\"], [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    print(\"Lower bound:\", lower_bound)\n",
    "    print(\"Upper bound:\", upper_bound)\n",
    "    outliers = data[(data[\"urlLenght\"] <= lower_bound) | (data[\"urlLenght\"] >= upper_bound)] \n",
    "    print(\"Numero di outlier: \", outliers.shape[0])\n",
    "    \n",
    "    count = outliers.label.value_counts()\n",
    "    print(\"numero outlier legitimate:\",count[\"legitimate\"])\n",
    "    print(\"numero outlier phishing:\",count[\"phishing\"])\n",
    "    \n",
    "    return lower_bound,upper_bound\n",
    "\n",
    "detectOutliers(finalDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e979e94-3456-43d3-a38b-ca559699c4fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Possiamo concludere che tutti gli Url che hanno la feature \"urlLenght\" che fuoriesce dai bound (Upper bound o Lower bound) sono da considerare outlier. Utilizzando il IQR method possiamo identificare ben 7123 outlier. Ovvero il 5% dell'intero dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b62e9e-b338-4236-9637-88c74ef875a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Eliminazione degli outlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc18b32-f7f0-4424-950e-e01f3abce73b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lower_bound,upper_bound = detectOutliers(finalDataset)\n",
    "\n",
    "#aggiorno il dataset scartando gli outliers\n",
    "finalDataset = finalDataset[(finalDataset[\"urlLenght\"] >= lower_bound) & (finalDataset[\"urlLenght\"] <= upper_bound)]\n",
    "\n",
    "#plotto il dataset aggiornato\n",
    "fig = px.box(finalDataset, x = \"label\", y=\"urlLenght\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf9185-2dac-4e06-bb6e-9c7727180dcf",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><font size=\"4\">Data visualization</font></b>\n",
    "\n",
    "in questa fase andremo ad <b>esplorare i dati</b> ed a <b>visualizzarli</b>. Inoltre andremo ad identificare le relazioni che ci sono fra i dati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6a24b-17ab-470f-a12f-287bfba2f4fe",
   "metadata": {},
   "source": [
    "Quello che andremo a fare in questo caso è andare a raffigurare i grafici in cui rappresentiamo sull'asse delle x la feature, mentre sull'asse delle y il numero di istanze. \n",
    "Queste informazioni potranno tornarci utili nella fase di \"Data preparation\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8309c2-f7b5-4266-a5f5-e3e97bd0d83d",
   "metadata": {},
   "source": [
    "In questa prima parte di grafici, andremo a valutare tutte le feature che hanno un valore numerico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887b021-e392-419e-9612-68a98fde04dc",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<b><font size=\"3\">Lunghezza del sottodominio (lenghtSub)</font></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664fb4d2-e295-44ba-9f1f-c4014c7a5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "legitimate = finalDataset[finalDataset['label'] == \"legitimate\"]\n",
    "phishing = finalDataset[finalDataset['label'] == \"phishing\"]\n",
    "\n",
    "plt.hist([legitimate['lenghtSub'], phishing['lenghtSub']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('lunghezza sottodominio')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a8cc8-0da1-4490-8adc-8d86ed79fe60",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\">Lunghezza dell' Url (urlLenght)</font></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0fd9d9-66e8-43c1-9b53-e74b1e9b0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['urlLenght'], phishing['urlLenght']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('lunghezza sottodominio')\n",
    "plt.title('lunghezza url')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9312d90-bbce-4a8a-bfa5-26fc6b33007f",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\">Numero di cifre all'interno dell'Url (numDigits)</font></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba3802-d028-43c6-ad54-1b11bed4e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numDigits'], phishing['numDigits']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('umero cifre nel url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfac7b8-3f05-4aae-94fd-071dadb19449",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\">Numero di lettere all'interno dell'Url (numLetters)</font></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795e059-97cd-40da-992a-7ad8bf060253",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numLetters'], phishing['numLetters']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('numero lettere nell url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73314d89-cd87-4d79-a4ac-becc4c674026",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di '&' nell'Url (numAmpersand)</font></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e178919-10d4-4724-ae75-69b221d2ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numAmpersand'], phishing['numAmpersand']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di & nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e8def-ff8b-4fad-8a21-a65fbd043877",
   "metadata": {},
   "source": [
    " \n",
    "<br><br> <b><font size=\"3\">Numero di '-' nell'Url (numDash)</font></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f794e3-8e8e-4866-8cfb-a47cf836644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numDash'], phishing['numDash']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di - nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db174d-d510-409c-890c-cfd006c2d288",
   "metadata": {},
   "source": [
    "\n",
    "<br><br> <b><font size=\"3\">Numero di '@' nell'Url (numAt)</font></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12360302-82d7-4f38-adbb-1460af9cef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numAt'], phishing['numAt']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di @ nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb607aa3-8c2b-41f6-b3f4-4bffc67bcf0a",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di '?' nell'Url (numQM)</font></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66627804-1204-43b9-9ac8-85373f79b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numQM'], phishing['numQM']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di ? nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374e4cf-f25e-4624-879b-b2453a5d5232",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di '|' nell'Url (numVS)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efa98c-23c0-4d9b-9cd8-8b7002dd2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numVS'], phishing['numVS']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di | nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9601ced4-b17d-4e9b-9220-6fadf927dcc7",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di '=' nell'Url (numEqual)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84b418-ae89-4143-afd0-5bddc69fb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numEqual'], phishing['numEqual']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di = nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e309010-2e57-4e39-8c66-b4de254fa970",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di '_' nell'Url (numUnderscore)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46c283-dd4a-4791-ad58-e8d3a8ed7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numUnderscore'], phishing['numUnderscore']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di _ nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3ebf9-f203-4eb2-98a8-c562a38f1568",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di '˜' nell'Url (numTilde)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebe3e0-4521-4eca-b3ed-247e59c961c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numTilde'], phishing['numTilde']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di ˜ nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e912ab-c3be-412b-a8fb-5fcdfff422e4",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di '%' nell'Url (numPercente)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5514e-b105-44c5-b473-26fe8713838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numPercente'], phishing['numPercente']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di % nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff096e-29ed-4a75-9ad4-9e508fe3d111",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di '*' nell'Url (numAsterisc)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef4df1-e109-4a30-bad6-50f29e034e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numAsterisc'], phishing['numAsterisc']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di * nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89b614-b8d8-4c88-a5b2-dfc23734a9bc",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di '$' nell'Url (numDollar)</font></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923371c-170d-4cd3-aba4-111ee3b0663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['NumDollar'], phishing['NumDollar']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di $ nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ad7fc-9bb6-4f6e-ac65-56fa7f34d185",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di ';' nell'Url (numSC)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03673f3-b7ac-49eb-9888-353266de1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numSC'], phishing['numSC']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di ; nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc0e877-0647-410b-8039-e02f6077dc1b",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di ':' nell'Url (numColons)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba832599-2c27-410e-bc78-c92b580771a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numColons'], phishing['numColons']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di : nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ecee26-2fc5-4e5d-903a-4bcc9d3d60ba",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di ''' nell'Url (numSQ)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f27c8b-1e63-4160-9457-ea3b00426a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numSQ'], phishing['numSQ']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di \\' nell Url')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f66ac-4465-4978-8cdc-45673cfcbdf5",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Numero di sottodomini nell'Url (numberSub)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cbac35-ab90-43d5-92e3-53db950f8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['numberSub'], phishing['numberSub']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Numero di sottodomini')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7a995-c84c-4469-8605-8b882558ea19",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Lunghezza del dominio nell'Url (lenghtDom)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84289ca3-d110-4a99-9e77-348b0a28b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['lenghtDom'], phishing['lenghtDom']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Lunghezza del dominio')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf29e52-0f71-4a01-990a-96701608e5cb",
   "metadata": {},
   "source": [
    "<br><br> <b><font size=\"3\">Lunghezza del path nell'Url (lenghtPath)</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64f783-9edc-4c3c-87ec-434e29424128",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([legitimate['lenghtPath'], phishing['lenghtPath']], label=['legitimate', 'phishing'],color=['royalblue','red'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('numero istanze')\n",
    "plt.xlabel('Lungezza path')\n",
    "plt.title('distribuzione')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197517e-0576-49f5-92c2-64c841916ec7",
   "metadata": {},
   "source": [
    "<br> \n",
    "I prossimi grafici rappresentano tutte le feature che hanno valore booleano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f64649-6f92-4de8-b207-601b273488ed",
   "metadata": {},
   "source": [
    "<b><font size=\"3\"> Dettagli riguardo la feature: dash</font></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168bd4c5-3df2-42b9-a5be-f98bf33de073",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(12, 10))\n",
    "\n",
    "#estrai il numero di url che hanno il dash (per tutti gli url phishing)\n",
    "phishingDash = phishing[phishing[\"dash\"] == 1]\n",
    "phishingNoDash = phishing[phishing[\"dash\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishingDash.shape[0], phishingNoDash.shape[0]]\n",
    "labels = ['Dash', 'No Dash']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Dash in phishing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "#estrai il numero di url che hanno il dash (per tutti gli url legitimate)\n",
    "legitimateDash = legitimate[legitimate['dash'] == 1]\n",
    "legitimateNoDash = legitimate[legitimate['dash'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimateDash.shape[0], legitimateNoDash.shape[0]]\n",
    "labels = ['Dash', 'No Dash']\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Dash in legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "urlDash = finalDataset[finalDataset[\"dash\"] == 1]\n",
    "\n",
    "count = urlDash.label.value_counts()\n",
    "\n",
    "data = [count[\"legitimate\"], count[\"phishing\"]]\n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "#Nel grafico ax3, andiamo a graficare TUTTI gli Url che hanno usano il dash, nello specifico andremo a suddividere il grafico in phishing e legitimate \n",
    "ax3.set_title('Url using dash')\n",
    "ax3.pie(data, labels = labels,colors = colors, autopct='%.0f%%')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Url legitimate using dash\",count[\"legitimate\"])\n",
    "print(\"Url phishing using dash\",count[\"phishing\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4015b60-f56d-4579-9f61-9238312e22cf",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\"> Dettagli rigurdo la feature: ShortiningServ</font></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99797251-529f-4c34-9ffb-fd47f58e62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(11, 10))\n",
    "\n",
    "#estrai il numero di url che hanno il dash (per tutti gli url phishing)\n",
    "phishingShortServ = phishing[phishing[\"ShortiningServ\"] == 1]\n",
    "phishingNoShortServ = phishing[phishing[\"ShortiningServ\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishingShortServ.shape[0], phishingNoShortServ.shape[0]]\n",
    "labels = ['Using Short. Serv.', 'No Short. Serv.']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Phshing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "\n",
    "#estrai il numero di url che hanno il dash (per tutti gli url legitimate)\n",
    "legitimateShortServ = legitimate[legitimate['ShortiningServ'] == 1]\n",
    "legitimateNoShortServ = legitimate[legitimate['ShortiningServ'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimateShortServ.shape[0], legitimateNoShortServ.shape[0]]\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "fig.tight_layout(pad=6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax3 = plt.subplots(1,1, figsize=(3, 10))\n",
    "urlShortiningServ = finalDataset[finalDataset[\"ShortiningServ\"] == 1]\n",
    "count = urlShortiningServ.label.value_counts()\n",
    "\n",
    "\n",
    "#controllo sul numero di istanze legitimate o phishing\n",
    "if 'legitimate' not in count:\n",
    "    numLegit = 0\n",
    "else:\n",
    "    numLegit = count[\"legitimate\"]\n",
    "\n",
    "if 'phishing' not in count:\n",
    "    numPhish = 0\n",
    "else:\n",
    "    numPhish = count[\"phishing\"]\n",
    "\n",
    "\n",
    "data = [numLegit, numPhish]\n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "#Nel grafico ax3, andiamo a graficare TUTTI gli Url che hanno usano il dash, nello specifico andremo a suddividere il grafico in phishing e legitimate \n",
    "ax3.set_title('Url using Shortening Services')\n",
    "ax3.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Url legitimate using Shortening Services\",numLegit)\n",
    "print(\"Url phishing using Shortening Services\",numPhish)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d7c57-77ed-4b30-9690-7d7f38a5f89a",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\"> Dettagli rigurdo la feature: httpsDomSub</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4866bf-6b33-4eff-b22a-1e93c0fe4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15, 10))\n",
    "\n",
    "phishing1 = phishing[phishing[\"httpsDomSub\"] == 1]\n",
    "phishing0 = phishing[phishing[\"httpsDomSub\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishing1.shape[0], phishing0.shape[0]]\n",
    "labels = ['Yes Https', 'No Https']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Phshing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "legitimate1 = legitimate[legitimate['httpsDomSub'] == 1]\n",
    "legitimate0 = legitimate[legitimate['httpsDomSub'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimate1.shape[0], legitimate0.shape[0]]\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "final = finalDataset[finalDataset[\"httpsDomSub\"] == 1]\n",
    "count = final.label.value_counts()\n",
    "\n",
    "#controllo sul numero di istanze legitimate o phishing\n",
    "if 'legitimate' not in count:\n",
    "    numLegit = 0\n",
    "else:\n",
    "    numLegit = count[\"legitimate\"]\n",
    "\n",
    "if 'phishing' not in count:\n",
    "    numPhish = 0\n",
    "else:\n",
    "    numPhish = count[\"phishing\"]\n",
    "\n",
    "data = [numLegit,numPhish] \n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "ax3.set_title('Url with https in domain')\n",
    "ax3.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "fig.tight_layout(pad=6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Numero di url legitimate con https nel dominio\", numLegit)\n",
    "print(\"Numero di url phishing con https nel dominio\", numPhish)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d53fc-c98a-4b79-9bb9-d1386f909fbe",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\"> Dettagli rigurdo la feature: port</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32f90e-a638-41d9-99c8-b1f2d21ae4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15, 10))\n",
    "\n",
    "phishing1 = phishing[phishing[\"port\"] == 1]\n",
    "phishing0 = phishing[phishing[\"port\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishing1.shape[0], phishing0.shape[0]]\n",
    "labels = ['port in Url', 'No port in Url']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Phshing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "legitimate1 = legitimate[legitimate['port'] == 1]\n",
    "legitimate0 = legitimate[legitimate['port'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimate1.shape[0], legitimate0.shape[0]]\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "\n",
    "final = finalDataset[finalDataset[\"port\"] == 1]\n",
    "count = final.label.value_counts()\n",
    "\n",
    "#controllo sul numero di istanze legitimate o phishing\n",
    "if 'legitimate' not in count:\n",
    "    numLegit = 0\n",
    "else:\n",
    "    numLegit = count[\"legitimate\"]\n",
    "\n",
    "if 'phishing' not in count:\n",
    "    numPhish = 0\n",
    "else:\n",
    "    numPhish = count[\"phishing\"]\n",
    "\n",
    "data = [numLegit,numPhish]    \n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "ax3.set_title('Url with port in url')\n",
    "ax3.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "fig.tight_layout(pad=4)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Numero di url legitimate con port nell url\", numLegit)\n",
    "print(\"Numero di url phishing con port nell url\", numPhish)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c59630-f049-4d56-9783-e23465d53cb4",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\"> Dettagli rigurdo la feature: checkPath</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b427f-b201-4a5a-bdcd-7670066be55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15, 10))\n",
    "\n",
    "phishing1 = phishing[phishing[\"checkPath\"] == 1]\n",
    "phishing0 = phishing[phishing[\"checkPath\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishing1.shape[0], phishing0.shape[0]]\n",
    "labels = ['Contain txt,exe,js', 'No txt,exe,js']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Phshing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "legitimate1 = legitimate[legitimate['checkPath'] == 1]\n",
    "legitimate0 = legitimate[legitimate['checkPath'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimate1.shape[0], legitimate0.shape[0]]\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "\n",
    "final = finalDataset[finalDataset[\"checkPath\"] == 1]\n",
    "count = final.label.value_counts()\n",
    "\n",
    "if 'legitimate' not in count:\n",
    "    numLegit = 0\n",
    "else:\n",
    "    numLegit = count[\"legitimate\"]\n",
    "\n",
    "if 'phishing' not in count:\n",
    "    numPhish = 0\n",
    "else:\n",
    "    numPhish = count[\"phishing\"]\n",
    "    \n",
    "data = [numLegit,numPhish]  \n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "ax3.set_title('Url with .txt, .exe, .js')\n",
    "ax3.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "fig.tight_layout(pad=4)\n",
    "plt.show()\n",
    "\n",
    "print(\"Numero di url legitimate con parole come txt,exe,js \", numLegit)\n",
    "print(\"Numero di url phishing con come txt,exe,js\", numPhish)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a51692-bc36-4d01-96b5-a29ce616de9f",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\"> Dettagli rigurdo la feature: PunyCode</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358119e4-20c8-495b-aba4-ebb4e3619cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15, 10))\n",
    "\n",
    "phishing1 = phishing[phishing[\"PunyCode\"] == 1]\n",
    "phishing0 = phishing[phishing[\"PunyCode\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishing1.shape[0], phishing0.shape[0]]\n",
    "labels = ['Use PunyCode', 'Not using PunyCode']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Phshing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "legitimate1 = legitimate[legitimate['PunyCode'] == 1]\n",
    "legitimate0 = legitimate[legitimate['PunyCode'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimate1.shape[0], legitimate0.shape[0]]\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "\n",
    "final = finalDataset[finalDataset[\"PunyCode\"] == 1]\n",
    "count = final.label.value_counts()\n",
    "\n",
    "if 'legitimate' not in count:\n",
    "    numLegit = 0\n",
    "else:\n",
    "    numLegit = count[\"legitimate\"]\n",
    "\n",
    "if 'phishing' not in count:\n",
    "    numPhish = 0\n",
    "else:\n",
    "    numPhish = count[\"phishing\"]\n",
    "    \n",
    "data = [numLegit,numPhish]  \n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "ax3.set_title('Url using PunyCode')\n",
    "ax3.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "fig.tight_layout(pad=4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Numero di url legitimate con PunyCode \", numLegit)\n",
    "print(\"Numero di url phishing con PunyCode\", numPhish)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ec651-5b13-4783-ada9-71dc5d1c5e51",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\"> Dettagli rigurdo la feature: suspWords</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e9d30-5d67-4027-b83d-77df53e60a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(16, 20))\n",
    "\n",
    "phishing1 = phishing[phishing[\"suspWords\"] == 1]\n",
    "phishing0 = phishing[phishing[\"suspWords\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishing1.shape[0], phishing0.shape[0]]\n",
    "labels = ['Using suspWords', 'Not using suspWords']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Phshing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "legitimate1 = legitimate[legitimate['suspWords'] == 1]\n",
    "legitimate0 = legitimate[legitimate['suspWords'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimate1.shape[0], legitimate0.shape[0]]\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "\n",
    "final = finalDataset[finalDataset[\"suspWords\"] == 1]\n",
    "count = final.label.value_counts()\n",
    "\n",
    "if 'legitimate' not in count:\n",
    "    numLegit = 0\n",
    "else:\n",
    "    numLegit = count[\"legitimate\"]\n",
    "\n",
    "if 'phishing' not in count:\n",
    "    numPhish = 0\n",
    "else:\n",
    "    numPhish = count[\"phishing\"]\n",
    "    \n",
    "data = [numLegit,numPhish]  \n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "ax3.set_title('Url using suspWords')\n",
    "ax3.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "fig.tight_layout(pad=3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Numero di url legitimate con suspWords \", numLegit)\n",
    "print(\"Numero di url phishing con suspWords\", numPhish)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9acff5-c21e-40e8-828e-f9a6f83a189f",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\"> Dettagli rigurdo la feature: https</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9e7a0-ce49-4045-97dc-75e92632dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15, 10))\n",
    "\n",
    "phishing1 = phishing[phishing[\"https\"] == 1]\n",
    "phishing0 = phishing[phishing[\"https\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishing1.shape[0], phishing0.shape[0]]\n",
    "labels = ['Using https', 'Not using https']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Phshing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "legitimate1 = legitimate[legitimate['https'] == 1]\n",
    "legitimate0 = legitimate[legitimate['https'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimate1.shape[0], legitimate0.shape[0]]\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "final = finalDataset[finalDataset[\"https\"] == 1]\n",
    "count = final.label.value_counts()\n",
    "\n",
    "if 'legitimate' not in count:\n",
    "    numLegit = 0\n",
    "else:\n",
    "    numLegit = count[\"legitimate\"]\n",
    "\n",
    "if 'phishing' not in count:\n",
    "    numPhish = 0\n",
    "else:\n",
    "    numPhish = count[\"phishing\"]\n",
    "\n",
    "data = [numLegit,numPhish]  \n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "ax3.set_title('Url using https')\n",
    "ax3.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "fig.tight_layout(pad=6)\n",
    "plt.show()\n",
    "\n",
    "print(\"Numero di url legitimate che usano https\", numLegit)\n",
    "print(\"Numero di url phishing che usano https\", numPhish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f2117-b9cc-4635-bcce-539a922663aa",
   "metadata": {},
   "source": [
    "Questo grafico fa notare un dettaglio interessante, nello specifico nel grafico \"Legitimate Url\" possiamo notare che solo il 27% degli Url legittimi utilizzano il protocollo https, mentre il restante degli url legittimi (ovvero il 73%) utilizza il protocollo http.Chiaramente ricordiamo che <b>non stiamo considerando tutti gli Url</b> in quanto molti di questi non hanno nessuna informazione riguardo il protocollo. \n",
    "\n",
    "Anche questo è un dettaglio che utilizzaremo in fase di \"Data preparation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f2b83-220d-4a04-8b17-a5cf42ef6cc0",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\"> Dettagli rigurdo la feature: email</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1cd9a-efab-48cc-92a2-6d1e0489e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(18, 10))\n",
    "\n",
    "phishing1 = phishing[phishing[\"email\"] == 1]\n",
    "phishing0 = phishing[phishing[\"email\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishing1.shape[0], phishing0.shape[0]]\n",
    "labels = ['Using email', 'Not using email']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Phshing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "legitimate1 = legitimate[legitimate['email'] == 1]\n",
    "legitimate0 = legitimate[legitimate['email'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimate1.shape[0], legitimate0.shape[0]]\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "\n",
    "final = finalDataset[finalDataset[\"email\"] == 1]\n",
    "count = final.label.value_counts()\n",
    "\n",
    "if 'legitimate' not in count:\n",
    "    numLegit = 0\n",
    "else:\n",
    "    numLegit = count[\"legitimate\"]\n",
    "\n",
    "if 'phishing' not in count:\n",
    "    numPhish = 0\n",
    "else:\n",
    "    numPhish = count[\"phishing\"]\n",
    "\n",
    "data = [numLegit,numPhish]  \n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "ax3.set_title('Url using email')\n",
    "ax3.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "fig.tight_layout(pad=6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Numero di url legitimate che usano email\", numLegit)\n",
    "print(\"Numero di url phishing che usano email\", numPhish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb7991-6b70-4b15-964f-c97b4aad094b",
   "metadata": {},
   "source": [
    "<br><br><b><font size=\"3\"> Dettagli rigurdo la feature: IP</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4564366-43ba-4ec8-9ce7-cf63e3b8fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15, 10))\n",
    "\n",
    "phishing1 = phishing[phishing[\"IP\"] == 1]\n",
    "phishing0 = phishing[phishing[\"IP\"] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [phishing1.shape[0], phishing0.shape[0]]\n",
    "labels = ['Using IP', 'Not using IP']\n",
    "colors = [\"salmon\",\"red\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax1.set_title('Phshing Url')\n",
    "ax1.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "legitimate1 = legitimate[legitimate['IP'] == 1]\n",
    "legitimate0 = legitimate[legitimate['IP'] == 0]\n",
    "\n",
    "#imposta i dati da plottare \n",
    "data = [legitimate1.shape[0], legitimate0.shape[0]]\n",
    "colors = [\"lightskyblue\",\"royalblue\"]\n",
    "\n",
    "#plotta i dati\n",
    "ax2.set_title('Legitimate Url')\n",
    "ax2.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "\n",
    "\n",
    "final = finalDataset[finalDataset[\"IP\"] == 1]\n",
    "count = final.label.value_counts()\n",
    "\n",
    "#controllo sul numero di istanze legitimate o phishing \n",
    "if 'legitimate' not in count:\n",
    "    numLegit = 0\n",
    "else:\n",
    "    numLegit = count[\"legitimate\"]\n",
    "\n",
    "if 'phishing' not in count:\n",
    "    numPhish = 0\n",
    "else:\n",
    "    numPhish = count[\"phishing\"]\n",
    "\n",
    "data = [numLegit,numPhish]  \n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "ax3.set_title('Url using IP')\n",
    "ax3.pie(data, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "fig.tight_layout(pad=6)\n",
    "plt.show()\n",
    "\n",
    "print(\"Numero di url legitimate che usano IP\", numLegit)\n",
    "print(\"Numero di url phishing che usano IP\", numPhish)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113504a6-c549-40d8-9289-47e94ac9832c",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size=\"5\">Data preparation</font>\n",
    "\n",
    "Questa fase ha l’obbiettivo di passare dal dataset iniziale ad un dataset utilizzabile da un algoritmo di ML.\n",
    "\n",
    "Nello specifico in questa fase ci soffermeremo alla fase di:\n",
    " - Data cleaning\n",
    " - Feature scaling\n",
    " - Feature selection\n",
    " - Data balancing\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b0086-a412-4f00-a5a3-e84e9a51a545",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"4\"> <b>Data cleaning </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ded384-0515-4820-b08f-196235c91596",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "Abbiamo visto che avremo 197 duplicati, andremo ad eliminare i duplicati.\n",
    "\n",
    "Eliminazione dei duplicati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6dba4-03c3-42da-bb51-f760eb81b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDataset = finalDataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf355203-9bdd-4c5f-9839-231203af7ac4",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"4\"> Data imputation </font>\n",
    "<br>\n",
    "\n",
    "Per via dell'alto numero di valori null, e dato che tutti valori null sono dovuti alla feature \"https\" (maggiori dettagli nella documentazione), andremo ad eliminare la feature \"https\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a8b3a-3f3e-4035-b473-065e8fe310ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDataset.drop(\"https\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb380308-b2a7-4546-b90e-08145eb2456d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"4\"> <b>Feature scaling</b> </font>\n",
    "\n",
    "In questa fase non effettuo feature scaling, ma la effettuo dopo la fase di \"Modeling\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb49540-85bb-4f4e-855c-d3b066cdd657",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"4\"> <b>Feature selection</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230233c-fe1d-4f4d-bb91-4e8617f7043d",
   "metadata": {},
   "source": [
    "Le feature con bassa varianza sono:\n",
    "- numAt\n",
    "- numQM\n",
    "- numAmpersand\n",
    "- numVS\n",
    "- numUnderscore\n",
    "- numTilde\n",
    "- numAsterisc\n",
    "- NumDollar\n",
    "- numSC\n",
    "- numColons\n",
    "- numSQ\n",
    "- numPercente\n",
    "\n",
    "Dunque andremo ad eliminare le colonne dal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94366c-5ede-463f-b421-1005782361c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"numAt\",\"numQM\",\"numAmpersand\", \"numVS\",\"numUnderscore\",\"numTilde\",\"numAsterisc\",\"NumDollar\", \"numSC\",\"numColons\",\"numSQ\",\"numPercente\"]\n",
    "\n",
    "#copio il dataset in modo da avere disponibile il dataset originale\n",
    "fullFinalDataset = finalDataset.copy()\n",
    "\n",
    "#eliminiamo le colonne con le feature con bassa varianza\n",
    "finalDataset.drop(to_drop, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d5bf1-a409-4e72-bba9-d3a9bfca2cef",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size=\"4\">Eliminazione delle feature \"checkPath\"</font>\n",
    "\n",
    "La feature checkPath è stata eliminata in quanto non sembra essere una feature caratterizzante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d684f14f-76da-4682-8757-6099aed3a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N.B. runnare questa cella una sola volta, se runni più volte non funziona in quanto non trova più la colonna \"checkPath\" \n",
    "#eliminiamo la colonna \"checkPath\"\n",
    "finalDataset.drop(\"checkPath\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e25b5b-7a41-4c87-9b64-9304e53d1aa5",
   "metadata": {},
   "source": [
    "<br>\n",
    "Dopo l'eliminazione delle colonne facciamo un recap della situazione attuale: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d57531-77c5-484a-9c52-1e6e65a3b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c57e4f2-2b89-4713-a0f8-ed7022dd83bb",
   "metadata": {},
   "source": [
    "In questa fase abbiamo eliminato un totale di 14 colonne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de456a-9901-4cde-b1c7-37e21f3117dc",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>Data balancing</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba43514-0498-431b-bd5f-2ed8066bee6d",
   "metadata": {},
   "source": [
    "Come abbiamo visto nella fase precedente, il dataset è composto da un numero di istanze di Url leggittimi (51%) e Url phishing (49%), molto simili.\n",
    "Di conseguenza non abbiamo necessità di bilanciare i dati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c764311-01dc-4be8-8a65-81e8506ce8fc",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size=\"5\">Modeling</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1a4bb-3641-4ffa-bea0-c1c6d385903a",
   "metadata": {},
   "source": [
    "Algoritmi presi in esame (Maggiori dettagli nella documentazione): \n",
    "- Naive Bayes\n",
    "- Decision trees\n",
    "- Random forests\n",
    "- K-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9e793a-bea6-4a92-a996-fcde459e89a1",
   "metadata": {},
   "source": [
    "<br> importo le librerie necessarie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040ef44-fd45-4ee3-bf80-ea382054f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import zscore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a1129-bd6d-4a68-9c4d-2aadd7491d85",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>Suddivisione dei dati (80:10:10)</b> </font>\n",
    "<br>\n",
    "Il trainig set sarà composto dal 80% dell'intero dataset, il validation set dal 10%, ed il test set sarà composto dal restante 10%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d6a5f-b98e-4b95-afdb-72d806f8fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe contenente tutte le feature\n",
    "X = finalDataset[['IP',\"urlLenght\",\"ShortiningServ\",\"numDash\",\"numEqual\",\"dash\",\"httpsDomSub\",\"port\",\"numberSub\",\"lenghtDom\",\"lenghtSub\",\"lenghtPath\",\"numLetters\",\"numDigits\",\"email\",\"PunyCode\",\"suspWords\",\"TLD\"]]\n",
    "#dataframe contenente unicamente la label\n",
    "y = finalDataset['label']\n",
    "\n",
    "# definiamo i training set, composto dall'80% dell'intero dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "\n",
    "#utilizziamo il dataset rimanente per definire il validation set ed il test set \n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af40bd-e89f-4f7c-b7fd-bf703e45a081",
   "metadata": {},
   "source": [
    "<br>Alcuni dettagli riguardo lo split dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb662f-f983-4285-89ba-e7eb62dc0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "countTrain = y_train.value_counts()\n",
    "countValid = y_valid.value_counts()\n",
    "countTest = y_test.value_counts()\n",
    "\n",
    "dataTrain = [countTrain[\"legitimate\"], countTrain[\"phishing\"]]\n",
    "dataValid = [countValid[\"legitimate\"], countValid[\"phishing\"]]\n",
    "dataTest = [countTest[\"legitimate\"], countTest[\"phishing\"]]\n",
    "\n",
    "print(\"Train set:\")\n",
    "print(\"Numero url legittimi:\",countTrain[\"legitimate\"])\n",
    "print(\"Numero url phishing: \" ,countTrain[\"phishing\"])\n",
    "print(\"\\n\")\n",
    "print(\"Validation set:\")\n",
    "print(\"Numero url legittimi:\",countValid[\"legitimate\"])\n",
    "print(\"Numero url phishing: \" ,countValid[\"phishing\"])\n",
    "print(\"\\n\")\n",
    "print(\"Test set:\")\n",
    "print(\"Numero url legittimi:\",countTest[\"legitimate\"])\n",
    "print(\"Numero url phishing: \" ,countTest[\"phishing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4249b-e032-4caa-8d98-c8c64c683154",
   "metadata": {},
   "source": [
    "<br>Plottiamo la distribuzione delle classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7239c-c3b9-4674-beb7-7e01c00f1ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(10, 10))\n",
    "\n",
    "labels = ['legitimate', 'phishing']\n",
    "colors = [\"royalblue\",\"red\"]\n",
    "\n",
    "ax1.set_title('Training set')\n",
    "ax1.pie(dataTrain, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "ax2.set_title('Validation set')\n",
    "ax2.pie(dataValid, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "ax3.set_title('Test set')\n",
    "ax3.pie(dataTest, labels = labels,colors = colors,autopct='%.0f%%')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbdf863-821a-4887-b26d-03d07a32b877",
   "metadata": {},
   "source": [
    "La distribuzione rimane uguale a quella del dataset iniziale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad57fc3-f6f2-425f-bdeb-6add0f7a9f97",
   "metadata": {},
   "source": [
    "<br><font size=\"3\"> <b>Test su diversi classificatori</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22123f58-c68c-4f45-9eb9-df991fa70b5c",
   "metadata": {},
   "source": [
    "Come detto precedentemente, tutti i modelli verranno allenati sul training set e valuteremo le prestazioni del modello utilizzando il validation set \n",
    "\n",
    "Per valutare il modello utilizzeremo il metodo <i>classification_report</i> il quale fornisce un riepilogo sulle principali metriche di valutazione (precision, recall, f1-score) e plotteremo la confusion matrix.\n",
    "\n",
    "In questo progetto, per configurare i parametri dei modelli, utilizzeremo il Grid Search (maggiori dettagli nella documentazione del progetto).\n",
    "Prima di allenare un modello andremo sempre a trovare la migliore combinazione di parametri utilizzando il Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d448e-5f60-4c58-987a-84c5e3c2ab4a",
   "metadata": {},
   "source": [
    "<br><font size=\"3\"> <b>Naive Bayes</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4037bb8-94a8-4bb7-ac24-55172beb9455",
   "metadata": {},
   "source": [
    "Troviamo la miglior combinazione di parametri per il modello <i>GaussianNB</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260d41d-fe2f-4f8a-85d7-4b1549b876fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo la griglia dei parametri che dovremo testare sul modello\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6],\n",
    "    'priors': [None, [0.1, 0.9], [0.2, 0.8], [0.3, 0.7]]\n",
    "}\n",
    "\n",
    "# definiamo il classificatore\n",
    "modelGaussian = GaussianNB()\n",
    "\n",
    "#grid search\n",
    "grid_search = GridSearchCV(estimator=modelGaussian, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#stampiamo i parametri migliori ed il miglior punteggio (in base all'accuracy)\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4b50e1-7943-4bae-9846-9c5c7bc4f63d",
   "metadata": {},
   "source": [
    "otteremo che i parametri migliori (tra quelli definiti nella variabile) sono i seguenti:\n",
    "    <i>'priors': [0.1, 0.9], 'var_smoothing': 1e-06  </i>\n",
    "<br> Useremo tali parametri per allenare il modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a737b-5633-45a8-827c-eaa9912befc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impostiamo il modello\n",
    "modelGaussian = GaussianNB(priors = [0.1, 0.9], var_smoothing = 1e-06)\n",
    "\n",
    "#alleniamo il modello\n",
    "modelGaussian.fit(X_train, y_train)\n",
    "#il modello predice i validation data\n",
    "y_pred = modelGaussian.predict(X_valid)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid, y_pred))\n",
    "\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a591cd-76c4-4c6b-87b9-0b890ec8c510",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>Decision tree</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc670d-edb2-4d0c-aa42-fdbe9893bbce",
   "metadata": {},
   "source": [
    "Troviamo la miglior combinazione di parametri per il modello <i>DecisionTreeClassifier</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af173b-2c85-4dc3-bd29-81b30aeda29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    'max_depth': [None, 5, 10,7,15],\n",
    "    'min_samples_split': [2, 5,7,10],\n",
    "    'min_samples_leaf': [1, 2, 4,6]\n",
    "}\n",
    "\n",
    "modelDT = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=modelDT, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab2c85-c9d2-4ad9-b4cb-cc1bd10dfdf3",
   "metadata": {},
   "source": [
    "Otteremo questa lista di parametri:\n",
    "<i>criterion = 'log_loss', max_depth = 15, min_samples_leaf = 1, min_samples_split = 2 </i>\n",
    "\n",
    "Qundi useremo questi parametri nel nostro modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcfe4c9-4416-43da-bfd8-823e5ac09791",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDT = DecisionTreeClassifier(criterion = 'log_loss', max_depth = 15, min_samples_leaf = 1, min_samples_split = 2)\n",
    "modelDT.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelDT.predict(X_valid)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7303a8-252c-4b7c-a751-20b57ed9e6be",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>Random forests</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09991e7-3886-4a83-8dcc-c3a114c63cf2",
   "metadata": {},
   "source": [
    "Troviamo la miglior combinazione di parametri per il modello <i>RandomForestClassifier</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3eb84d-cda4-43e4-a490-d0410d1a811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "modelRF = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=modelRF, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3162bb-bdf2-46c0-b853-b38d76921a31",
   "metadata": {},
   "source": [
    "Otteremo questa lista di parametri: <i>max_depth = None, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 200 </i>\n",
    "\n",
    "Qundi useremo questi parametri nel nostro modello.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b73f9-7a06-43d0-9480-698f5163e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRF = RandomForestClassifier(max_depth = None, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 200)\n",
    "\n",
    "modelRF.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelRF.predict(X_valid)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5b5215-e35e-4cc7-8fdf-2b34f500a09c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>KNeighborsClassifier</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea7deb-ced5-4930-aabe-88b621d805e0",
   "metadata": {},
   "source": [
    "Troviamo la miglior combinazione di parametri per il modello <i>KNeighborsClassifier</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658195cc-4257-4c36-bc87-61a2548574d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1, 31), 'weights': ['uniform', 'distance']}\n",
    "\n",
    "modelKnn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=modelKnn, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a341d-57ca-4924-a56d-b9956823e519",
   "metadata": {},
   "source": [
    "Otteremo questa lista di parametri: <i> n_neighbors = 7, weight ='distance' </i>\n",
    "\n",
    "Qundi useremo questi parametri nel nostro modello.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23fbc8-8a3e-4821-9762-2e90cc91bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKnn = KNeighborsClassifier(n_neighbors = 7, weights ='distance')\n",
    "\n",
    "modelKnn.fit(X_train, y_train)\n",
    "y_pred = modelKnn.predict(X_valid)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid, y_pred))\n",
    "\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33d51e-ae63-4681-8db9-3be2448d76e5",
   "metadata": {},
   "source": [
    "Alla fine di questa fase possiamo osservare che il modello più prestante è RandomForestClassifier con i parametri <i> max_depth = None, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 200 </i>\n",
    "<br>\n",
    "Dunque sarà proprio questo il modello che utilizzeremo in fase di \"Evaluation\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e76b3-4476-455e-8388-e7039da3d064",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>Sperimentazione con suddivisione dei dati (60:20:20)</b> </font>\n",
    "<br>\n",
    "In questa fase andremo a sperimentare i modelli connuna diversa suddivisione del dataset.\n",
    "Il trainig set sarà composto dal 60% dell'intero dataset, il validation set dal 20%, ed il test set sarà composto dal restante 20%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24613c66-dddb-4199-bccd-3f4deecc9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe contenente tutte le feature\n",
    "X60 = finalDataset[['IP',\"urlLenght\",\"ShortiningServ\",\"numDash\",\"numEqual\",\"dash\",\"httpsDomSub\",\"port\",\"numberSub\",\"lenghtDom\",\"lenghtSub\",\"lenghtPath\",\"numLetters\",\"numDigits\",\"email\",\"PunyCode\",\"suspWords\",\"TLD\"]]\n",
    "\n",
    "#dataframe contenente unicamente la label\n",
    "y60 = finalDataset['label']\n",
    "\n",
    "# definiamo i training set, composto dall'60% dell'intero dataset\n",
    "X_train60, X_rem60, y_train60, y_rem60 = train_test_split(X60,y60, train_size=0.6)\n",
    "\n",
    "#utilizziamo il dataset rimanente per definire il validation set ed il test set \n",
    "X_valid60, X_test60, y_valid60, y_test60= train_test_split(X_rem60,y_rem60, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb360d-66e5-4d43-86cc-29151aff9d57",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> Dettagli sullo plitting: </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9c6c3-ec31-4f4c-882e-c11f0332a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "countTrain = y_train60.value_counts()\n",
    "countValid = y_valid60.value_counts()\n",
    "countTest = y_test.value_counts()\n",
    "\n",
    "dataTrain = [countTrain[\"legitimate\"], countTrain[\"phishing\"]]\n",
    "dataValid = [countValid[\"legitimate\"], countValid[\"phishing\"]]\n",
    "dataTest = [countTest[\"legitimate\"], countTest[\"phishing\"]]\n",
    "\n",
    "print(\"Train set:\")\n",
    "print(\"Numero url legittimi:\",countTrain[\"legitimate\"])\n",
    "print(\"Numero url phishing: \" ,countTrain[\"phishing\"])\n",
    "print(\"\\n\")\n",
    "print(\"Validation set:\")\n",
    "print(\"Numero url legittimi:\",countValid[\"legitimate\"])\n",
    "print(\"Numero url phishing: \" ,countValid[\"phishing\"])\n",
    "print(\"\\n\")\n",
    "print(\"Test set:\")\n",
    "print(\"Numero url legittimi:\",countTest[\"legitimate\"])\n",
    "print(\"Numero url phishing: \" ,countTest[\"phishing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231e882-3beb-463f-8827-11336260fd2d",
   "metadata": {},
   "source": [
    "<br><font size=\"3\"> <b>Naive Bayes</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c594eb2-9bde-43de-9fee-671e1ffc5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impostiamo il modello\n",
    "modelGaussian = GaussianNB(priors = [0.1, 0.9], var_smoothing = 1e-06)\n",
    "\n",
    "#alleniamo il modello\n",
    "modelGaussian.fit(X_train60, y_train60)\n",
    "#il modello predice i validation data\n",
    "y_pred = modelGaussian.predict(X_valid60)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid60, y_pred))\n",
    "\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid60, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007b110-9a83-4f0d-a342-c91a5a207033",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>Decision tree</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59410e7-3014-42d9-b086-25a9052b55cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDT = DecisionTreeClassifier(criterion = 'entropy', max_depth = None, min_samples_leaf = 6, min_samples_split = 2 )\n",
    "modelDT.fit(X_train60, y_train60)\n",
    "\n",
    "y_pred = modelDT.predict(X_valid60)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid60, y_pred))\n",
    "\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid60, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78456a25-b4b9-451f-a21d-f709c6b5fa84",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>Random forests</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5567860e-f43a-4078-a5ac-34c0059a0d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRF = RandomForestClassifier(max_depth = None, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 200)\n",
    "\n",
    "modelRF.fit(X_train60, y_train60)\n",
    "\n",
    "y_pred = modelRF.predict(X_valid60)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid60, y_pred))\n",
    "   \n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid60, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fca44c-c808-49f0-be27-5b640ca67e00",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>KNNeighbors</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803d594-7c49-4589-8c82-6ed3b11c08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKnn = KNeighborsClassifier(n_neighbors = 7, weights ='distance')\n",
    "\n",
    "modelKnn.fit(X_train60, y_train60)\n",
    "y_pred = modelKnn.predict(X_valid60)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid60, y_pred))\n",
    "\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid60, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c1921-f302-406c-8bdb-01545f3a2ac8",
   "metadata": {},
   "source": [
    "Per quanto riguarda lo splitting, <b>non ci sono alcune differenze nelle performance dei modelli</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b16b2-d2f0-4e60-a46c-fd94eb580f0c",
   "metadata": {},
   "source": [
    "Ritorno alla fase di \"Data preparation\" (maggiori dettagli nella documantazione)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30feeff2-07ec-4979-a98f-55130e844554",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size=\"5\">Data preparation</font>\n",
    "<br>\n",
    "\n",
    "<font size=\"3\"> <b> Feature scaling </b> </font>\n",
    "<br>\n",
    "Prima di normalizzare i dati, per rappresentare la diversa distribuzione dei dati, plotto la il valore medio dei dati. \n",
    "\n",
    "Dunque guardiamo il valore medio di ogni singola colonna (feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3292fe-e441-442f-b879-2caa858353e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selezioniamo tutte le colonne che ci interessano in questo caso (ceh sono tutte quelle che hanno un valore numerico)\n",
    "numeric_cols = finalDataset.select_dtypes(include=['int64','float64']).columns\n",
    "\n",
    "for feature in numeric_cols:\n",
    "    print(\"Media di \",feature,\": \",finalDataset[feature].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89642403-f558-4e5b-bcc0-a0c8b78610c9",
   "metadata": {},
   "source": [
    "Già da questo output possiamo vedere che, alcune feature hanno distribuzioni molto diverse rispetto ad altre, guardiamo ad esempio \"urlLenght\" e \"email\".\n",
    "Per avere un idea migliore possiamo plottare i dati: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795a53e-ed59-4c4b-a31d-cd6ccd5a8c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values = []\n",
    "col_names = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # calcoliamo la media della colonna\n",
    "    mean = finalDataset[col].mean()\n",
    "    mean_values.append(mean)\n",
    "    col_names.append(col)\n",
    "\n",
    "#plottiamo il grafico    \n",
    "fig, ax1 = plt.subplots(figsize=(25, 8), dpi=1000)\n",
    "ax1.bar(col_names, mean_values)\n",
    "plt.xlabel('features')\n",
    "plt.ylabel('Valore medio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac67c03-bb4a-4dd0-ae9e-0df81ba936e3",
   "metadata": {},
   "source": [
    "In questa fase veidamo graficamente la diversa distribuzione delle feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723a0d4-fd70-4209-a926-c4a0ddd120af",
   "metadata": {},
   "source": [
    "<br>\n",
    "andiamo a normalizzare il dataset utilizzando lo <b> z-score normalization</b>. Ovviamente andremo a normalizzare unicamente le colonne numeriche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3f1fd-2a3f-4cfc-8244-95c0b2767fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleziono le colonne da normalizzare, quindi selezioni le feature escludendo url e label dalla normalizzazione\n",
    "columns = ['IP',\"urlLenght\",\"ShortiningServ\",\"numDash\",\"numEqual\",\"dash\",\"httpsDomSub\",\"port\",\"numberSub\",\"lenghtDom\",\"lenghtSub\",\"lenghtPath\",\"numLetters\",\"numDigits\",\"email\",\"PunyCode\",\"suspWords\",\"TLD\"]\n",
    "zScoreFinalDataset = finalDataset[columns].apply(zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f5b7a4-b49b-4089-bf1b-2ab6acecad05",
   "metadata": {},
   "source": [
    "<br>\n",
    "Un esempio del risultato della normalizzazione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1d61a-877f-41a1-a256-a1453b890ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zScoreFinalDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eef785-2723-499c-bd69-ec2dc802dc9d",
   "metadata": {},
   "source": [
    "Adesso torniamo alla fase di \"Modeling\" e controlliamo le prestazioni dei modelli dopo la normalizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dcb770-2825-40b4-aeec-7f7ee17b7818",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size=\"5\">Modeling</font>\n",
    "\n",
    "<font size=\"3\"><b>Split dei dati</b></font>\n",
    "\n",
    "Chiaramente dobbiamo suddividere i dati nuovamente, in quanto dobbiamo allenare e valutare i modelli sui dati normalizzati.\n",
    "Di conseguenza nella prossima fase andremo a suddividere i dati con la stessa modalità della fase precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3dc69-0f25-41da-936c-e5a9f5b4593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe contenente tutte le feature\n",
    "X_norm = zScoreFinalDataset[columns]\n",
    "\n",
    "#dataframe contenente unicamente la label\n",
    "y = finalDataset['label']\n",
    "\n",
    "# definiamo i training set, composto dall'80% dell'intero dataset\n",
    "X_train_norm, X_rem_norm, y_train_norm, y_rem_norm = train_test_split(X_norm,y, train_size=0.8)\n",
    "\n",
    "#utilizziamo il dataset rimanente per definire il validation set ed il test set \n",
    "X_valid_norm, X_test_norm, y_valid_norm, y_test_norm = train_test_split(X_rem_norm,y_rem_norm, test_size=0.5)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50882bf9-1906-4c81-a531-142e30b1a237",
   "metadata": {},
   "source": [
    "<br>\n",
    "Adesso, esattamente come nella fase di Modeling precedente, andremo nuovamente a ricercare i parametri migliori per ogni singolo modello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9279aed-c2ef-4ecb-a003-62c56333dd07",
   "metadata": {},
   "source": [
    "<br><font size=\"3\"> <b>Naive Bayes</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d853107-5b58-4cc0-80e4-02cb83087bc8",
   "metadata": {},
   "source": [
    "Cerchiamo la miglior combinazione di parametri per il modello e con il dataset normalizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89527ae-b39f-45d8-b32a-233cefdc325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6],\n",
    "    'priors': [None, [0.1, 0.9], [0.2, 0.8], [0.3, 0.7]]\n",
    "}\n",
    "\n",
    "# modello gaussiano per dataset normalizzato\n",
    "modelGaussianNorm = GaussianNB()\n",
    "\n",
    "# Initialize the grid search\n",
    "grid_search = GridSearchCV(estimator=modelGaussianNorm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e20aa6a-ae4c-4dd7-9ccb-3161f49bb807",
   "metadata": {},
   "source": [
    "Otteremo la stessa lista di parametri del modello precedente ovvero: <i>priors = [0.1, 0.9], var_smoothing = 1e-06 </i> \n",
    "Usiamo questi parametri per allenare il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1d49e-4f54-49b7-9874-67b7b77db93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGaussianNorm = GaussianNB(priors = [0.1, 0.9], var_smoothing = 1e-06)\n",
    "\n",
    "modelGaussianNorm.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "y_pred = modelGaussianNorm.predict(X_valid_norm)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid_norm, y_pred))\n",
    "\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid_norm, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4ae15-b811-480a-8105-439f5f30a81c",
   "metadata": {},
   "source": [
    "<br><font size=\"3\"> <b>Decision Tree</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30997f6d-fb8d-46cd-933a-ef551840f60c",
   "metadata": {},
   "source": [
    "Cerchiamo la miglior combinazione di parametri per il modello e con il dataset normalizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284acfa1-482b-40e8-9074-2c6ca3de78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    'max_depth': [None, 5, 10,7,15],\n",
    "    'min_samples_split': [2, 5,7,10],\n",
    "    'min_samples_leaf': [1, 2, 4,6]\n",
    "}\n",
    "\n",
    "modelDTNorm = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=modelDTNorm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867cb5d5-b460-467a-bc1a-100518f7a344",
   "metadata": {},
   "source": [
    "In questo caso, la migliore combinazione di parametri è <i> criterion ='entropy', max_depth = None, min_samples_leaf =6, min_samples_split = 2 </i> \n",
    "Usiamo questi parametri per allenare il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c2a3b-2f15-4801-bbc4-23487fde8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDTNorm = DecisionTreeClassifier(criterion ='entropy', max_depth = None, min_samples_leaf =6, min_samples_split = 2)\n",
    "\n",
    "modelDTNorm.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "y_pred = modelDTNorm.predict(X_valid_norm)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid_norm, y_pred))\n",
    "\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid_norm, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb7b97-0143-48e8-8830-583d9c802cb2",
   "metadata": {},
   "source": [
    "<br><font size=\"3\"> <b>RandomForest</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f6ad1a-6ddd-4acf-8001-0aa4337a0eb1",
   "metadata": {},
   "source": [
    "Cerchiamo la miglior combinazione di parametri per il modello e con il dataset normalizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a7944-63b5-40b8-b9c8-359669c1976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "modelRFNorm = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=modelRFNorm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d3d85-4dae-4712-ac9f-7692eb3bc5e2",
   "metadata": {},
   "source": [
    "Otteremo la stessa lista di parametri : <i> max_depth = None, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 200</i> \n",
    "Usiamo questi parametri per allenare il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52868517-0688-4c17-97fe-841cf07b5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRFNorm = RandomForestClassifier(max_depth = None, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 200)\n",
    "\n",
    "modelRFNorm.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "y_pred = modelRFNorm.predict(X_valid_norm)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid_norm, y_pred))\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid_norm, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b42e23-24c6-4c6f-ac93-2d925a583434",
   "metadata": {},
   "source": [
    "<br><font size=\"3\"> <b>KNeighborsClassifier</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848400bd-fcf2-48f8-8b0c-9bb04cbd3809",
   "metadata": {},
   "source": [
    "Cerchiamo la miglior combinazione di parametri per il modello e con il dataset normalizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a6630-5004-424f-aa90-68bfd8b3b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': np.arange(1, 31), 'weights': ['uniform', 'distance']}\n",
    "\n",
    "modelKnnNorm = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=modelKnnNorm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5739c-f0f8-4748-89ff-96274dc486d5",
   "metadata": {},
   "source": [
    "Otteremo la stessa lista di parametri: <i> n_neighbors = 8, weights = 'distance' </i> \n",
    "Usiamo questi parametri per allenare il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53e1ee-30a9-4699-bf56-3cf22c7fe443",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKnnNorm = KNeighborsClassifier(n_neighbors = 8, weights = 'distance')\n",
    "\n",
    "modelKnnNorm.fit(X_train_norm, y_train_norm)\n",
    "y_pred = modelKnnNorm.predict(X_valid_norm)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_valid_norm, y_pred))\n",
    "\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_valid_norm, y_pred)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5866cf04-b1a5-4657-8e27-8d16a969cc45",
   "metadata": {},
   "source": [
    "\n",
    "Come è possibile vedere dalle metriche dei modelli, la normalizzazione del dataset <b>non ha portato un aumento delle prestazioni</b>, anzi, in alcuni modelli come il GaussianNB ha portato ad un degrado delle prestazioni. \n",
    "\n",
    "Di conseguenza sceglieremo il modello <i>RandomForestClassifier</i> utilizzando i parametri <i>max_depth = None, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 200 </i> allenato su dati non normalizzati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8370bc8-d280-47c0-915d-22d3bad11439",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size=\"5\">Evaluation</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad134b-bb5d-4120-8cf4-32b481df88d4",
   "metadata": {},
   "source": [
    "In questa fase andremo a valutare l’accuratezza del modello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada3454-dd6d-46a1-8bf7-75993fa9138f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"><b>Valutazione del modello</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da7f314-6d26-4d29-afc0-812596aaca99",
   "metadata": {},
   "source": [
    "Dato che la normalizzazione non ha portato miglioramenti nella prestazione dei modelli, utilizzo il modello allenato su dati non normalizzati(ovvero modelRF).\n",
    "Nella prossima fase andremo a validare il modello con gli insiemi di test non normalizzati(X_test e y_test) prodotti in fase di \"Modeling\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd2c95-1342-444e-9f51-d93a73bea9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelRF è il modello Random Forest Classifier allenato su dati non normalizzati\n",
    "y_prediction = modelRF.predict(X_test)\n",
    "\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_prediction))\n",
    "print('Confusion_matrix')\n",
    "cf_matrix = confusion_matrix(y_test, y_prediction)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd6601a-2815-4037-bfa7-888aa32fa57d",
   "metadata": {},
   "source": [
    "Otterremo dunque il nostro modello finale. \n",
    "\n",
    "Dalla fase di \"Modeling\" possiamo passara a due diverse fasi. Nel caso in cui gli obbiettivi di business non sono stati raggiunti, è necessario tornare alla fase di \"Business understanding\" per ricominciare il ciclo.\n",
    "\n",
    "Nel caso in cui invece tutti gli obbiettivi di business sono stati raggiunti possiamo passare alla fase di \"Deployment\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f1a41-3d9e-46a9-86e9-1f1bde1567ac",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size=\"5\">Deployment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b773a742-d7c9-45bb-b0ff-59e827c1fe55",
   "metadata": {},
   "source": [
    "Per la fase di deployment, decido di creare un piccolo applicativo capace di utilizzare il modello appena creato.\n",
    "\n",
    "L'applicazione non verrà sviluppata in questo notebook, ma è possibile trovarla nel file <i>Demo.py</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186767e-e836-4284-aa1c-b1f05dc52e46",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\"> <b>salva il modello</b> </font>\n",
    "<br>\n",
    "Salviamo il modello in un file .joblib, ed utilizzeremo questo file per caricare il modello nell'applicazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a477b68-a99a-4cc7-aded-22460a36ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(modelRF, 'modelRF.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17395bb6-f3ac-40b7-9793-7870bfeedb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "infine vorrei aggiungere un ultima osservazione RIGUARDO FEAURE VS TUTTE LE FEATURE "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb82f1d377885c7be8803c9bb537832f14456c61b0efd1d822e9df9153e87753"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
